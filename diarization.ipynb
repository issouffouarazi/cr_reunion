{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a05ad53-b463-4913-b7f0-c401bdc43c4f",
   "metadata": {},
   "source": [
    "# openai whisper + pyannote\n",
    "\n",
    "* https://github.com/openai/whisper\n",
    "* https://github.com/pyannote/pyannote-audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f72fa83-b5d3-4a98-89b6-90bc7442dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, glob, os\n",
    "import subprocess\n",
    "# send pipeline to GPU (when available)\n",
    "import torch\n",
    "import whisper\n",
    "import pyannote.audio\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from pyannote.audio import Audio\n",
    "from pyannote.core import Segment\n",
    "import main_meetsum\n",
    "import ollama\n",
    "\n",
    "\n",
    "import wave\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937de523-1b6e-47c5-ac19-f4a5d8611b11",
   "metadata": {},
   "source": [
    "## whisper speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594f6cb-d59f-4230-8432-9948ddf4a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_whisper():\n",
    "\tfiles = glob.glob('*.mp4')\n",
    "\tcmd = ''\n",
    "\tfor f in files:\n",
    "\t\tname=os.path.splitext(f)[0]\n",
    "\t\tprint (name)\n",
    "\t\tif os.path.exists(name):\n",
    "\t\t\tcontinue\n",
    "\t\tcmd += 'whisper {} --device cuda --model medium --language en -o {} && '.format(f,name)\n",
    "\t\t#print (cmd)\n",
    "\t\t#subprocess.check_output(cmd,shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8249c180-d48b-42a6-91e2-f325ff1ea0ab",
   "metadata": {},
   "source": [
    "## basic diarization with pyannote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00e85b-766b-49ed-ada6-8125eae1a718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0.3s stop=4.2s speaker_SPEAKER_01\n",
      "start=4.9s stop=9.9s speaker_SPEAKER_00\n",
      "start=10.0s stop=10.0s speaker_SPEAKER_00\n",
      "start=10.1s stop=12.5s speaker_SPEAKER_00\n",
      "start=13.0s stop=14.3s speaker_SPEAKER_00\n",
      "start=15.0s stop=15.6s speaker_SPEAKER_00\n",
      "start=16.2s stop=18.1s speaker_SPEAKER_02\n",
      "start=18.4s stop=19.0s speaker_SPEAKER_00\n",
      "start=19.4s stop=20.8s speaker_SPEAKER_00\n",
      "start=21.1s stop=27.4s speaker_SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\")\n",
    "# pipeline.to(torch.device(\"cuda\"))\n",
    "# apply pretrained pipeline\n",
    "diarization = pipeline(\"test.wav\")\n",
    "\n",
    "# print the result\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec95ad-1601-4763-9950-5bb39b49edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"audio.rttm\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8e609-5eb1-481b-93f2-5a9440013edc",
   "metadata": {},
   "source": [
    "## extract speakers with whisper/pyannote\n",
    "\n",
    "https://colab.research.google.com/drive/1V-Bt5Hm2kjaDb4P1RyMSswsDKyrzc2-3?usp=sharing#scrollTo=buGt4moR5Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddba543-006e-465f-b26e-7928d0fdbbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
    "embedding_model = PretrainedSpeakerEmbedding( \n",
    "    \"speechbrain/spkrec-ecapa-voxceleb\") #,    device=torch.device(\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cd07e9b9-ec94-4d9d-8c33-876414e13ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [05:30<00:00, 9.34MiB/s]\n"
     ]
    }
   ],
   "source": [
    "language = 'fr' #@param ['any', 'English']\n",
    "model_size = 'tiny' #@param ['tiny', 'base', 'small', 'medium', 'large']\n",
    "model = whisper.load_model('large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3725aedd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m segments \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/whisper/transcribe.py:240\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    237\u001b[0m mel_segment \u001b[38;5;241m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[1;32m    239\u001b[0m decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 240\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/whisper/transcribe.py:170\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    167\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    169\u001b[0m options \u001b[38;5;241m=\u001b[39m DecodingOptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, temperature\u001b[38;5;241m=\u001b[39mt)\n\u001b[0;32m--> 170\u001b[0m decode_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    174\u001b[0m     compression_ratio_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m decode_result\u001b[38;5;241m.\u001b[39mcompression_ratio \u001b[38;5;241m>\u001b[39m compression_ratio_threshold\n\u001b[1;32m    176\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/whisper/decoding.py:824\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    822\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 824\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/whisper/decoding.py:737\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    734\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(audio_features\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    736\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[1;32m    740\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m audio_features[:: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group]\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/whisper/decoding.py:687\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_len):\n\u001b[0;32m--> 687\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    690\u001b[0m             i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mno_speech \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    691\u001b[0m         ):  \u001b[38;5;66;03m# save no_speech_probs\u001b[39;00m\n\u001b[1;32m    692\u001b[0m             probs_at_sot \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msot_index]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/whisper/decoding.py:163\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_token_length:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/whisper/model.py:211\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    208\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(xa\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 211\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[1;32m    214\u001b[0m logits \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    215\u001b[0m     x \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    216\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/whisper/model.py:136\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    131\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     kv_cache: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m ):\n\u001b[0;32m--> 136\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_ln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[1;32m    138\u001b[0m         x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn_ln(x), xa, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/whisper/model.py:84\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kv_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m xa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kv_cache:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# hooks, if installed (i.e. kv_cache is not None), will prepend the cached kv tensors;\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# otherwise, perform key/value projections for self- or cross-attention as usual.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(x \u001b[38;5;28;01mif\u001b[39;00m xa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m xa)\n\u001b[0;32m---> 84\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m(x \u001b[38;5;28;01mif\u001b[39;00m xa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m xa)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# for cross-attention, calculate keys and values once and reuse in subsequent calls.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     k \u001b[38;5;241m=\u001b[39m kv_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey]\n",
      "File \u001b[0;32m~/anaconda3/envs/kernel_3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:1696\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1698\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"medium\")\n",
    "path = \"test.mp3\"\n",
    "result = model.transcribe(path, language  = \"fr\")\n",
    "segments = result[\"segments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8111419f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'seek': 0,\n",
       "  'start': 0.0,\n",
       "  'end': 4.44,\n",
       "  'text': \" Aujourd'hui, en reçoit si mal un étudiant de 19 ans passionné à d'électronique.\",\n",
       "  'tokens': [50364,\n",
       "   32650,\n",
       "   6,\n",
       "   10556,\n",
       "   11,\n",
       "   465,\n",
       "   319,\n",
       "   8560,\n",
       "   270,\n",
       "   1511,\n",
       "   2806,\n",
       "   517,\n",
       "   4823,\n",
       "   532,\n",
       "   5798,\n",
       "   368,\n",
       "   1294,\n",
       "   1567,\n",
       "   5418,\n",
       "   15055,\n",
       "   1531,\n",
       "   274,\n",
       "   6,\n",
       "   526,\n",
       "   1809,\n",
       "   2044,\n",
       "   1925,\n",
       "   13,\n",
       "   50586],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.28899504235908813,\n",
       "  'compression_ratio': 1.6239067055393586,\n",
       "  'no_speech_prob': 0.018904877826571465},\n",
       " {'id': 1,\n",
       "  'seek': 0,\n",
       "  'start': 4.44,\n",
       "  'end': 8.44,\n",
       "  'text': \" Il s'est donné le défi fou de fabriquer son propre processeur.\",\n",
       "  'tokens': [50586,\n",
       "   4416,\n",
       "   262,\n",
       "   6,\n",
       "   377,\n",
       "   31165,\n",
       "   476,\n",
       "   2795,\n",
       "   13325,\n",
       "   32012,\n",
       "   368,\n",
       "   5355,\n",
       "   470,\n",
       "   8035,\n",
       "   1872,\n",
       "   35221,\n",
       "   17565,\n",
       "   405,\n",
       "   374,\n",
       "   13,\n",
       "   50786],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.28899504235908813,\n",
       "  'compression_ratio': 1.6239067055393586,\n",
       "  'no_speech_prob': 0.018904877826571465},\n",
       " {'id': 2,\n",
       "  'seek': 0,\n",
       "  'start': 8.44,\n",
       "  'end': 11.64,\n",
       "  'text': \" Alors, je peux vous dire, fabriquer un processeur, c'est quand même un sacré défi.\",\n",
       "  'tokens': [50786,\n",
       "   9946,\n",
       "   11,\n",
       "   1506,\n",
       "   14844,\n",
       "   2630,\n",
       "   1264,\n",
       "   11,\n",
       "   5355,\n",
       "   470,\n",
       "   8035,\n",
       "   517,\n",
       "   17565,\n",
       "   405,\n",
       "   374,\n",
       "   11,\n",
       "   269,\n",
       "   6,\n",
       "   377,\n",
       "   6932,\n",
       "   5698,\n",
       "   517,\n",
       "   7480,\n",
       "   526,\n",
       "   2795,\n",
       "   13325,\n",
       "   13,\n",
       "   50946],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.28899504235908813,\n",
       "  'compression_ratio': 1.6239067055393586,\n",
       "  'no_speech_prob': 0.018904877826571465},\n",
       " {'id': 3,\n",
       "  'seek': 0,\n",
       "  'start': 11.64,\n",
       "  'end': 13.92,\n",
       "  'text': \" C'est l'éléments central de leur dynamiteur.\",\n",
       "  'tokens': [50946,\n",
       "   383,\n",
       "   6,\n",
       "   377,\n",
       "   287,\n",
       "   6,\n",
       "   19559,\n",
       "   1117,\n",
       "   5777,\n",
       "   368,\n",
       "   9580,\n",
       "   5999,\n",
       "   642,\n",
       "   374,\n",
       "   13,\n",
       "   51060],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.28899504235908813,\n",
       "  'compression_ratio': 1.6239067055393586,\n",
       "  'no_speech_prob': 0.018904877826571465},\n",
       " {'id': 4,\n",
       "  'seek': 0,\n",
       "  'start': 13.92,\n",
       "  'end': 16.080000000000002,\n",
       "  'text': ' Surtout potentiellement le plus complexe,',\n",
       "  'tokens': [51060,\n",
       "   318,\n",
       "   6224,\n",
       "   346,\n",
       "   27073,\n",
       "   32562,\n",
       "   1712,\n",
       "   476,\n",
       "   1804,\n",
       "   3997,\n",
       "   68,\n",
       "   11,\n",
       "   51168],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.28899504235908813,\n",
       "  'compression_ratio': 1.6239067055393586,\n",
       "  'no_speech_prob': 0.018904877826571465},\n",
       " {'id': 5,\n",
       "  'seek': 0,\n",
       "  'start': 16.080000000000002,\n",
       "  'end': 19.080000000000002,\n",
       "  'text': \" si mal tu es venu avec ta maquette, justement, que qu'on a là,\",\n",
       "  'tokens': [51168,\n",
       "   1511,\n",
       "   2806,\n",
       "   2604,\n",
       "   785,\n",
       "   6138,\n",
       "   84,\n",
       "   4163,\n",
       "   1846,\n",
       "   463,\n",
       "   358,\n",
       "   3007,\n",
       "   11,\n",
       "   27807,\n",
       "   11,\n",
       "   631,\n",
       "   421,\n",
       "   6,\n",
       "   266,\n",
       "   257,\n",
       "   3684,\n",
       "   11,\n",
       "   51318],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.28899504235908813,\n",
       "  'compression_ratio': 1.6239067055393586,\n",
       "  'no_speech_prob': 0.018904877826571465},\n",
       " {'id': 6,\n",
       "  'seek': 0,\n",
       "  'start': 19.080000000000002,\n",
       "  'end': 23.52,\n",
       "  'text': ' tu vas pouvoir nous expliquer comment ta réaliser ce qui est,',\n",
       "  'tokens': [51318,\n",
       "   2604,\n",
       "   11481,\n",
       "   14874,\n",
       "   4666,\n",
       "   1490,\n",
       "   23909,\n",
       "   2871,\n",
       "   1846,\n",
       "   18911,\n",
       "   6694,\n",
       "   1769,\n",
       "   1956,\n",
       "   871,\n",
       "   11,\n",
       "   51540],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.28899504235908813,\n",
       "  'compression_ratio': 1.6239067055393586,\n",
       "  'no_speech_prob': 0.018904877826571465},\n",
       " {'id': 7,\n",
       "  'seek': 0,\n",
       "  'start': 23.52,\n",
       "  'end': 27.0,\n",
       "  'text': ' ou ce qui peut être va bientôt être une vraie architecture de processeurs,',\n",
       "  'tokens': [51540,\n",
       "   2820,\n",
       "   1769,\n",
       "   1956,\n",
       "   5977,\n",
       "   7418,\n",
       "   2773,\n",
       "   34653,\n",
       "   7418,\n",
       "   2251,\n",
       "   6070,\n",
       "   414,\n",
       "   9482,\n",
       "   368,\n",
       "   17565,\n",
       "   405,\n",
       "   2156,\n",
       "   11,\n",
       "   51714],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.28899504235908813,\n",
       "  'compression_ratio': 1.6239067055393586,\n",
       "  'no_speech_prob': 0.018904877826571465},\n",
       " {'id': 8,\n",
       "  'seek': 0,\n",
       "  'start': 27.0,\n",
       "  'end': 28.6,\n",
       "  'text': \" puisqu'il marche à priori.\",\n",
       "  'tokens': [51714, 43459, 6, 388, 32631, 1531, 4059, 72, 13, 51794],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.28899504235908813,\n",
       "  'compression_ratio': 1.6239067055393586,\n",
       "  'no_speech_prob': 0.018904877826571465},\n",
       " {'id': 9,\n",
       "  'seek': 2860,\n",
       "  'start': 28.720000000000002,\n",
       "  'end': 31.48,\n",
       "  'text': \" Et ce sera l'occasion pour tous les gens qui n'ont, comme nous,\",\n",
       "  'tokens': [50370,\n",
       "   3790,\n",
       "   1769,\n",
       "   15021,\n",
       "   287,\n",
       "   6,\n",
       "   43280,\n",
       "   6822,\n",
       "   2016,\n",
       "   8317,\n",
       "   1512,\n",
       "   10668,\n",
       "   1956,\n",
       "   297,\n",
       "   6,\n",
       "   896,\n",
       "   11,\n",
       "   5173,\n",
       "   4666,\n",
       "   11,\n",
       "   50508],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3517999712205091,\n",
       "  'compression_ratio': 1.5911764705882352,\n",
       "  'no_speech_prob': 0.010566827841103077},\n",
       " {'id': 10,\n",
       "  'seek': 2860,\n",
       "  'start': 31.48,\n",
       "  'end': 36.08,\n",
       "  'text': ' jamais compris exactement ce qui se passait au cœur de notre ordinateur,',\n",
       "  'tokens': [50508,\n",
       "   14540,\n",
       "   31711,\n",
       "   38111,\n",
       "   1769,\n",
       "   1956,\n",
       "   369,\n",
       "   1320,\n",
       "   1001,\n",
       "   1609,\n",
       "   43207,\n",
       "   368,\n",
       "   10349,\n",
       "   4792,\n",
       "   13923,\n",
       "   374,\n",
       "   11,\n",
       "   50738],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3517999712205091,\n",
       "  'compression_ratio': 1.5911764705882352,\n",
       "  'no_speech_prob': 0.010566827841103077},\n",
       " {'id': 11,\n",
       "  'seek': 2860,\n",
       "  'start': 36.08,\n",
       "  'end': 38.08,\n",
       "  'text': \" à pas d'y voir un petit peu plus clair, justement.\",\n",
       "  'tokens': [50738,\n",
       "   1531,\n",
       "   1736,\n",
       "   274,\n",
       "   6,\n",
       "   88,\n",
       "   10695,\n",
       "   517,\n",
       "   9686,\n",
       "   5604,\n",
       "   1804,\n",
       "   41375,\n",
       "   11,\n",
       "   27807,\n",
       "   13,\n",
       "   50838],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3517999712205091,\n",
       "  'compression_ratio': 1.5911764705882352,\n",
       "  'no_speech_prob': 0.010566827841103077},\n",
       " {'id': 12,\n",
       "  'seek': 2860,\n",
       "  'start': 38.08,\n",
       "  'end': 40.88,\n",
       "  'text': \" En prévu, est-ce que tu peux nous s'expliquer pourquoi tu t'élances\",\n",
       "  'tokens': [50838,\n",
       "   2193,\n",
       "   11127,\n",
       "   32257,\n",
       "   11,\n",
       "   871,\n",
       "   12,\n",
       "   384,\n",
       "   631,\n",
       "   2604,\n",
       "   14844,\n",
       "   4666,\n",
       "   262,\n",
       "   6,\n",
       "   23040,\n",
       "   23909,\n",
       "   19934,\n",
       "   2604,\n",
       "   256,\n",
       "   6,\n",
       "   526,\n",
       "   8658,\n",
       "   887,\n",
       "   50978],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3517999712205091,\n",
       "  'compression_ratio': 1.5911764705882352,\n",
       "  'no_speech_prob': 0.010566827841103077},\n",
       " {'id': 13,\n",
       "  'seek': 2860,\n",
       "  'start': 40.88,\n",
       "  'end': 42.6,\n",
       "  'text': ' dans ce défi complètement dingue déjà ?',\n",
       "  'tokens': [50978,\n",
       "   2680,\n",
       "   1769,\n",
       "   2795,\n",
       "   13325,\n",
       "   31331,\n",
       "   21211,\n",
       "   622,\n",
       "   12027,\n",
       "   2506,\n",
       "   51064],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3517999712205091,\n",
       "  'compression_ratio': 1.5911764705882352,\n",
       "  'no_speech_prob': 0.010566827841103077},\n",
       " {'id': 14,\n",
       "  'seek': 2860,\n",
       "  'start': 42.6,\n",
       "  'end': 46.6,\n",
       "  'text': \" Déjà, parce que je m'amuse à chercher comment font son de les choses depuis toujours.\",\n",
       "  'tokens': [51064,\n",
       "   31153,\n",
       "   11313,\n",
       "   11,\n",
       "   6992,\n",
       "   631,\n",
       "   1506,\n",
       "   275,\n",
       "   6,\n",
       "   335,\n",
       "   438,\n",
       "   1531,\n",
       "   38747,\n",
       "   2871,\n",
       "   10703,\n",
       "   1872,\n",
       "   368,\n",
       "   1512,\n",
       "   14488,\n",
       "   16062,\n",
       "   11936,\n",
       "   13,\n",
       "   51264],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3517999712205091,\n",
       "  'compression_ratio': 1.5911764705882352,\n",
       "  'no_speech_prob': 0.010566827841103077},\n",
       " {'id': 15,\n",
       "  'seek': 2860,\n",
       "  'start': 46.6,\n",
       "  'end': 47.96,\n",
       "  'text': ' Je suis extrêmement curieux.',\n",
       "  'tokens': [51264, 2588, 7624, 38148, 1262, 35371, 13, 51332],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3517999712205091,\n",
       "  'compression_ratio': 1.5911764705882352,\n",
       "  'no_speech_prob': 0.010566827841103077},\n",
       " {'id': 16,\n",
       "  'seek': 2860,\n",
       "  'start': 47.96,\n",
       "  'end': 50.92,\n",
       "  'text': ' Donc ça va regarder des protocoles comme le GP,',\n",
       "  'tokens': [51332,\n",
       "   7477,\n",
       "   2788,\n",
       "   2773,\n",
       "   31468,\n",
       "   730,\n",
       "   10336,\n",
       "   279,\n",
       "   5173,\n",
       "   476,\n",
       "   26039,\n",
       "   11,\n",
       "   51480],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3517999712205091,\n",
       "  'compression_ratio': 1.5911764705882352,\n",
       "  'no_speech_prob': 0.010566827841103077},\n",
       " {'id': 17,\n",
       "  'seek': 2860,\n",
       "  'start': 50.92,\n",
       "  'end': 54.6,\n",
       "  'text': ' qui puis comprendre comment il marche directement en organes similes.',\n",
       "  'tokens': [51480,\n",
       "   1956,\n",
       "   9093,\n",
       "   26856,\n",
       "   2871,\n",
       "   1930,\n",
       "   32631,\n",
       "   37297,\n",
       "   465,\n",
       "   1798,\n",
       "   279,\n",
       "   1034,\n",
       "   4680,\n",
       "   13,\n",
       "   51664],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3517999712205091,\n",
       "  'compression_ratio': 1.5911764705882352,\n",
       "  'no_speech_prob': 0.010566827841103077},\n",
       " {'id': 18,\n",
       "  'seek': 5460,\n",
       "  'start': 54.72,\n",
       "  'end': 59.480000000000004,\n",
       "  'text': \" Et l'algorithme YouTube a fait que j'ai commencé à plonger dans des petites niches.\",\n",
       "  'tokens': [50370,\n",
       "   3790,\n",
       "   287,\n",
       "   6,\n",
       "   20422,\n",
       "   6819,\n",
       "   1398,\n",
       "   3088,\n",
       "   257,\n",
       "   3887,\n",
       "   631,\n",
       "   361,\n",
       "   6,\n",
       "   1301,\n",
       "   37561,\n",
       "   1531,\n",
       "   499,\n",
       "   556,\n",
       "   260,\n",
       "   2680,\n",
       "   730,\n",
       "   34063,\n",
       "   25570,\n",
       "   279,\n",
       "   13,\n",
       "   50608],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2905881881713867,\n",
       "  'compression_ratio': 1.657492354740061,\n",
       "  'no_speech_prob': 0.22412748634815216},\n",
       " {'id': 19,\n",
       "  'seek': 5460,\n",
       "  'start': 59.480000000000004,\n",
       "  'end': 61.800000000000004,\n",
       "  'text': \" Et je suis tombé sur la chaîne d'un YouTubeur américain,\",\n",
       "  'tokens': [50608,\n",
       "   3790,\n",
       "   1506,\n",
       "   7624,\n",
       "   18712,\n",
       "   526,\n",
       "   1022,\n",
       "   635,\n",
       "   28036,\n",
       "   274,\n",
       "   6,\n",
       "   409,\n",
       "   3088,\n",
       "   374,\n",
       "   39902,\n",
       "   491,\n",
       "   11,\n",
       "   50724],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2905881881713867,\n",
       "  'compression_ratio': 1.657492354740061,\n",
       "  'no_speech_prob': 0.22412748634815216},\n",
       " {'id': 20,\n",
       "  'seek': 5460,\n",
       "  'start': 61.800000000000004,\n",
       "  'end': 63.400000000000006,\n",
       "  'text': \" qui s'appelle Ben Nitter.\",\n",
       "  'tokens': [50724, 1956, 262, 6, 25543, 3964, 426, 3904, 13, 50804],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2905881881713867,\n",
       "  'compression_ratio': 1.657492354740061,\n",
       "  'no_speech_prob': 0.22412748634815216},\n",
       " {'id': 21,\n",
       "  'seek': 5460,\n",
       "  'start': 63.400000000000006,\n",
       "  'end': 66.88,\n",
       "  'text': \" Et donc c'est lui qui construit en premier cette machine.\",\n",
       "  'tokens': [50804,\n",
       "   3790,\n",
       "   5926,\n",
       "   269,\n",
       "   6,\n",
       "   377,\n",
       "   8783,\n",
       "   1956,\n",
       "   12946,\n",
       "   270,\n",
       "   465,\n",
       "   12689,\n",
       "   5550,\n",
       "   3479,\n",
       "   13,\n",
       "   50978],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2905881881713867,\n",
       "  'compression_ratio': 1.657492354740061,\n",
       "  'no_speech_prob': 0.22412748634815216},\n",
       " {'id': 22,\n",
       "  'seek': 5460,\n",
       "  'start': 66.88,\n",
       "  'end': 68.6,\n",
       "  'text': \" Donc je ne m'attriviu pas tous les laurels,\",\n",
       "  'tokens': [50978,\n",
       "   7477,\n",
       "   1506,\n",
       "   408,\n",
       "   275,\n",
       "   6,\n",
       "   1591,\n",
       "   470,\n",
       "   4917,\n",
       "   84,\n",
       "   1736,\n",
       "   8317,\n",
       "   1512,\n",
       "   49469,\n",
       "   11784,\n",
       "   11,\n",
       "   51064],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2905881881713867,\n",
       "  'compression_ratio': 1.657492354740061,\n",
       "  'no_speech_prob': 0.22412748634815216},\n",
       " {'id': 23,\n",
       "  'seek': 5460,\n",
       "  'start': 68.6,\n",
       "  'end': 70.8,\n",
       "  'text': \" c'est quand même pas uniquement mon travail.\",\n",
       "  'tokens': [51064,\n",
       "   269,\n",
       "   6,\n",
       "   377,\n",
       "   6932,\n",
       "   5698,\n",
       "   1736,\n",
       "   20763,\n",
       "   1712,\n",
       "   1108,\n",
       "   18047,\n",
       "   13,\n",
       "   51174],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2905881881713867,\n",
       "  'compression_ratio': 1.657492354740061,\n",
       "  'no_speech_prob': 0.22412748634815216},\n",
       " {'id': 24,\n",
       "  'seek': 5460,\n",
       "  'start': 70.8,\n",
       "  'end': 72.72,\n",
       "  'text': \" Et un moment, j'ai sauté le bas, j'ai acheté tous les composants,\",\n",
       "  'tokens': [51174,\n",
       "   3790,\n",
       "   517,\n",
       "   1623,\n",
       "   11,\n",
       "   361,\n",
       "   6,\n",
       "   1301,\n",
       "   601,\n",
       "   325,\n",
       "   526,\n",
       "   476,\n",
       "   987,\n",
       "   11,\n",
       "   361,\n",
       "   6,\n",
       "   1301,\n",
       "   2800,\n",
       "   41739,\n",
       "   8317,\n",
       "   1512,\n",
       "   10199,\n",
       "   1719,\n",
       "   11,\n",
       "   51270],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2905881881713867,\n",
       "  'compression_ratio': 1.657492354740061,\n",
       "  'no_speech_prob': 0.22412748634815216},\n",
       " {'id': 25,\n",
       "  'seek': 5460,\n",
       "  'start': 72.72,\n",
       "  'end': 74.44,\n",
       "  'text': \" et j'ai commencé à construire le mien.\",\n",
       "  'tokens': [51270,\n",
       "   1030,\n",
       "   361,\n",
       "   6,\n",
       "   1301,\n",
       "   37561,\n",
       "   1531,\n",
       "   12946,\n",
       "   621,\n",
       "   476,\n",
       "   275,\n",
       "   1053,\n",
       "   13,\n",
       "   51356],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2905881881713867,\n",
       "  'compression_ratio': 1.657492354740061,\n",
       "  'no_speech_prob': 0.22412748634815216},\n",
       " {'id': 26,\n",
       "  'seek': 5460,\n",
       "  'start': 74.44,\n",
       "  'end': 78.0,\n",
       "  'text': \" Et ton objectif, c'est de créer un processeur,\",\n",
       "  'tokens': [51356,\n",
       "   3790,\n",
       "   2952,\n",
       "   2657,\n",
       "   351,\n",
       "   11,\n",
       "   269,\n",
       "   6,\n",
       "   377,\n",
       "   368,\n",
       "   32062,\n",
       "   517,\n",
       "   17565,\n",
       "   405,\n",
       "   374,\n",
       "   11,\n",
       "   51534],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2905881881713867,\n",
       "  'compression_ratio': 1.657492354740061,\n",
       "  'no_speech_prob': 0.22412748634815216},\n",
       " {'id': 27,\n",
       "  'seek': 5460,\n",
       "  'start': 78.0,\n",
       "  'end': 80.88,\n",
       "  'text': ' à ce que, à partir de quoi, on peut appeler ça, un processeur.',\n",
       "  'tokens': [51534,\n",
       "   1531,\n",
       "   1769,\n",
       "   631,\n",
       "   11,\n",
       "   1531,\n",
       "   13906,\n",
       "   368,\n",
       "   11714,\n",
       "   11,\n",
       "   322,\n",
       "   5977,\n",
       "   724,\n",
       "   6185,\n",
       "   2788,\n",
       "   11,\n",
       "   517,\n",
       "   17565,\n",
       "   405,\n",
       "   374,\n",
       "   13,\n",
       "   51678],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2905881881713867,\n",
       "  'compression_ratio': 1.657492354740061,\n",
       "  'no_speech_prob': 0.22412748634815216},\n",
       " {'id': 28,\n",
       "  'seek': 8088,\n",
       "  'start': 80.88,\n",
       "  'end': 84.67999999999999,\n",
       "  'text': \" C'est compliqué à dire, d'autant plus que c'est pas complètement un processeur,\",\n",
       "  'tokens': [50364,\n",
       "   383,\n",
       "   6,\n",
       "   377,\n",
       "   44290,\n",
       "   1531,\n",
       "   1264,\n",
       "   11,\n",
       "   274,\n",
       "   6,\n",
       "   1375,\n",
       "   394,\n",
       "   1804,\n",
       "   631,\n",
       "   269,\n",
       "   6,\n",
       "   377,\n",
       "   1736,\n",
       "   31331,\n",
       "   517,\n",
       "   17565,\n",
       "   405,\n",
       "   374,\n",
       "   11,\n",
       "   50554],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.22954753222386481,\n",
       "  'compression_ratio': 1.7253086419753085,\n",
       "  'no_speech_prob': 0.13545775413513184},\n",
       " {'id': 29,\n",
       "  'seek': 8088,\n",
       "  'start': 84.67999999999999,\n",
       "  'end': 87.19999999999999,\n",
       "  'text': ' dans le sens où il y a carrément une sortie, il y a un affichage,',\n",
       "  'tokens': [50554,\n",
       "   2680,\n",
       "   476,\n",
       "   2923,\n",
       "   9068,\n",
       "   1930,\n",
       "   288,\n",
       "   257,\n",
       "   1032,\n",
       "   10521,\n",
       "   518,\n",
       "   2251,\n",
       "   45662,\n",
       "   11,\n",
       "   1930,\n",
       "   288,\n",
       "   257,\n",
       "   517,\n",
       "   2096,\n",
       "   480,\n",
       "   609,\n",
       "   11,\n",
       "   50680],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.22954753222386481,\n",
       "  'compression_ratio': 1.7253086419753085,\n",
       "  'no_speech_prob': 0.13545775413513184},\n",
       " {'id': 30,\n",
       "  'seek': 8088,\n",
       "  'start': 87.19999999999999,\n",
       "  'end': 90.64,\n",
       "  'text': \" il y a de l'arame, alors que l'arame, c'est plutôt en dehors d'un processeur.\",\n",
       "  'tokens': [50680,\n",
       "   1930,\n",
       "   288,\n",
       "   257,\n",
       "   368,\n",
       "   287,\n",
       "   6,\n",
       "   289,\n",
       "   529,\n",
       "   11,\n",
       "   11246,\n",
       "   631,\n",
       "   287,\n",
       "   6,\n",
       "   289,\n",
       "   529,\n",
       "   11,\n",
       "   269,\n",
       "   6,\n",
       "   377,\n",
       "   20856,\n",
       "   465,\n",
       "   36892,\n",
       "   830,\n",
       "   274,\n",
       "   6,\n",
       "   409,\n",
       "   17565,\n",
       "   405,\n",
       "   374,\n",
       "   13,\n",
       "   50852],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.22954753222386481,\n",
       "  'compression_ratio': 1.7253086419753085,\n",
       "  'no_speech_prob': 0.13545775413513184},\n",
       " {'id': 31,\n",
       "  'seek': 8088,\n",
       "  'start': 90.64,\n",
       "  'end': 93.75999999999999,\n",
       "  'text': \" Mais c'est en fait une machine, ça se dit Turine Complete.\",\n",
       "  'tokens': [50852,\n",
       "   6313,\n",
       "   269,\n",
       "   6,\n",
       "   377,\n",
       "   465,\n",
       "   3887,\n",
       "   2251,\n",
       "   3479,\n",
       "   11,\n",
       "   2788,\n",
       "   369,\n",
       "   6176,\n",
       "   5712,\n",
       "   533,\n",
       "   34687,\n",
       "   13,\n",
       "   51008],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.22954753222386481,\n",
       "  'compression_ratio': 1.7253086419753085,\n",
       "  'no_speech_prob': 0.13545775413513184},\n",
       " {'id': 32,\n",
       "  'seek': 8088,\n",
       "  'start': 93.75999999999999,\n",
       "  'end': 96.36,\n",
       "  'text': \" Donc il faudrait définir ce que c'est qu'il y a une machine de Turine.\",\n",
       "  'tokens': [51008,\n",
       "   7477,\n",
       "   1930,\n",
       "   38694,\n",
       "   8645,\n",
       "   40763,\n",
       "   347,\n",
       "   1769,\n",
       "   631,\n",
       "   269,\n",
       "   6,\n",
       "   377,\n",
       "   421,\n",
       "   6,\n",
       "   388,\n",
       "   288,\n",
       "   257,\n",
       "   2251,\n",
       "   3479,\n",
       "   368,\n",
       "   5712,\n",
       "   533,\n",
       "   13,\n",
       "   51138],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.22954753222386481,\n",
       "  'compression_ratio': 1.7253086419753085,\n",
       "  'no_speech_prob': 0.13545775413513184},\n",
       " {'id': 33,\n",
       "  'seek': 8088,\n",
       "  'start': 96.36,\n",
       "  'end': 100.16,\n",
       "  'text': \" C'est un concept hypothétique créé par Alan Turine en 1936,\",\n",
       "  'tokens': [51138,\n",
       "   383,\n",
       "   6,\n",
       "   377,\n",
       "   517,\n",
       "   3410,\n",
       "   24371,\n",
       "   42379,\n",
       "   15609,\n",
       "   526,\n",
       "   971,\n",
       "   16442,\n",
       "   5712,\n",
       "   533,\n",
       "   465,\n",
       "   1294,\n",
       "   11309,\n",
       "   11,\n",
       "   51328],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.22954753222386481,\n",
       "  'compression_ratio': 1.7253086419753085,\n",
       "  'no_speech_prob': 0.13545775413513184},\n",
       " {'id': 34,\n",
       "  'seek': 8088,\n",
       "  'start': 100.16,\n",
       "  'end': 104.67999999999999,\n",
       "  'text': ' et qui nous définit une bande de papiers infinie,',\n",
       "  'tokens': [51328,\n",
       "   1030,\n",
       "   1956,\n",
       "   4666,\n",
       "   40763,\n",
       "   270,\n",
       "   2251,\n",
       "   46836,\n",
       "   368,\n",
       "   5806,\n",
       "   4890,\n",
       "   7193,\n",
       "   414,\n",
       "   11,\n",
       "   51554],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.22954753222386481,\n",
       "  'compression_ratio': 1.7253086419753085,\n",
       "  'no_speech_prob': 0.13545775413513184},\n",
       " {'id': 35,\n",
       "  'seek': 8088,\n",
       "  'start': 104.67999999999999,\n",
       "  'end': 106.28,\n",
       "  'text': ' composée de plein de cases,',\n",
       "  'tokens': [51554, 10199, 3856, 368, 21088, 368, 3331, 11, 51634],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.22954753222386481,\n",
       "  'compression_ratio': 1.7253086419753085,\n",
       "  'no_speech_prob': 0.13545775413513184},\n",
       " {'id': 36,\n",
       "  'seek': 8088,\n",
       "  'start': 106.28,\n",
       "  'end': 109.03999999999999,\n",
       "  'text': ' et une tête de lecture qui peut écrire sur une case,',\n",
       "  'tokens': [51634,\n",
       "   1030,\n",
       "   2251,\n",
       "   24661,\n",
       "   368,\n",
       "   7991,\n",
       "   1956,\n",
       "   5977,\n",
       "   1136,\n",
       "   39572,\n",
       "   1022,\n",
       "   2251,\n",
       "   1389,\n",
       "   11,\n",
       "   51772],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.22954753222386481,\n",
       "  'compression_ratio': 1.7253086419753085,\n",
       "  'no_speech_prob': 0.13545775413513184}]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "22045494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def segments2json(segments, save = True) : \n",
    "    segments_json = []\n",
    "    for seg in segments : \n",
    "        segments_json.append(\n",
    "            { \"speaker\" : seg[\"seek\"],\n",
    "             \"text\" : seg[\"text\"]\n",
    "            }\n",
    "        )\n",
    "    if save : \n",
    "        with open (\"meeting_transcript.json\",\"w\",  encoding='utf-8') as f:\n",
    "            json.dump(segments_json,f, ensure_ascii=False)\n",
    "\n",
    "    return segments_json\n",
    "\n",
    "\n",
    "segments_json = segments2json(segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "26fc6851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Aujourd'hui, en reçoit Simon a une étudiante de 19 ans passionné à déliter un dix\n",
      "0  et le défi fou de fabriquer son propre processeur.\n",
      "0  Alors, je peux vous dire, fabriquer un processeur, c'est quand même un sacré défi.\n",
      "0  C'est l'élement centrale de l'ordinateur, surtout, potent ainsi le plus complexe.\n",
      "0  Simon, tu as venu avec ta maquette, justement, qu'on a là, tu vas pouvoir nous expliquer comment\n",
      "0  t'arriéliser ce qui est, ou ce qui peut être va bien to être une vraie architecture de processeur\n",
      "0  puisque il marche à priori.\n",
      "2860  Et ce sera l'occasion pour tous les gens qui donnent comme nous.\n",
      "2860  J'ai aimé compris exactement ce qui se passait au cœur de notre ordinateur,\n",
      "2860  à pas de voir un petit peu plus clair, justement.\n",
      "2860  En préavus, est-ce que tu peux nous s'expliquer pourquoi tu t'élencesse dans ce défi complètement d'un défi?\n",
      "2860  Déjà, parce que je m'amuse à chercher comment font son déchose depuis toujours.\n",
      "2860  Je suis extrêmement courieux.\n",
      "2860  Ça va les regarder des protocales comme le GP-E, qui est puis comprendre comment il marche directement au dégain d'ici-mal.\n",
      "5440  Et la algorithme YouTube a fait que j'ai commencé à plonger dans des petites niches.\n",
      "5440  Et je suis tombé sur la chaîne d'un YouTube-Armer American, qui s'appelle Ben Interre.\n",
      "5440  Et donc c'est lui qui construit en premier cette machine, donc je me mettrai peu pas tous les loriers, c'est quand même pas uniquement mon travail.\n",
      "5440  Et en moins j'ai sauté le bâge, j'ai acheté tous les composants et j'ai commencé à construire le mur.\n",
      "5440  Et donc ton objectif, c'est de créer un processeur parce que, à partir de quand on peut appeler ça, un processeur.\n",
      "8080  Tu compliques à dire, de temps plus que c'est pas complètement un processeur.\n",
      "8080  Dans le sens où il y a carrément une sortie, il y a un affichage, il y a de la rampe alors que la rampe serait plutôt en dehors dans un processeur.\n",
      "8080  Mais c'est en fait une machine, ça se dit « Tourine complique ».\n",
      "8080  Donc il faut réd définir ce que c'est qu'une machine de Tourine.\n",
      "8080  C'est un concept typothétique créé par Alan Tourine en 1936.\n",
      "8080  Et qui nous définit une bande de papier infinie, composée de plein de casse,\n",
      "10620  et une tête de lecture qui peut écrire sur une casse.\n",
      "1  :   Aujourd'hui, en reçoit Simon a une étudiante de 19 ans passionné à déliter un dix\n",
      "2  :   et le défi fou de fabriquer son propre processeur.\n",
      "3  :   Alors, je peux vous dire, fabriquer un processeur, c'est quand même un sacré défi.\n",
      "4  :   C'est l'élement centrale de l'ordinateur, surtout, potent ainsi le plus complexe.\n",
      "5  :   Simon, tu as venu avec ta maquette, justement, qu'on a là, tu vas pouvoir nous expliquer comment\n",
      "6  :   t'arriéliser ce qui est, ou ce qui peut être va bien to être une vraie architecture de processeur\n",
      "7  :   puisque il marche à priori.\n",
      "1  :   Et ce sera l'occasion pour tous les gens qui donnent comme nous.\n",
      "2  :   J'ai aimé compris exactement ce qui se passait au cœur de notre ordinateur,\n",
      "3  :   à pas de voir un petit peu plus clair, justement.\n",
      "4  :   En préavus, est-ce que tu peux nous s'expliquer pourquoi tu t'élencesse dans ce défi complètement d'un défi?\n",
      "5  :   Déjà, parce que je m'amuse à chercher comment font son déchose depuis toujours.\n",
      "6  :   Je suis extrêmement courieux.\n",
      "7  :   Ça va les regarder des protocales comme le GP-E, qui est puis comprendre comment il marche directement au dégain d'ici-mal.\n",
      "1  :   Et la algorithme YouTube a fait que j'ai commencé à plonger dans des petites niches.\n",
      "2  :   Et je suis tombé sur la chaîne d'un YouTube-Armer American, qui s'appelle Ben Interre.\n",
      "3  :   Et donc c'est lui qui construit en premier cette machine, donc je me mettrai peu pas tous les loriers, c'est quand même pas uniquement mon travail.\n",
      "4  :   Et en moins j'ai sauté le bâge, j'ai acheté tous les composants et j'ai commencé à construire le mur.\n",
      "5  :   Et donc ton objectif, c'est de créer un processeur parce que, à partir de quand on peut appeler ça, un processeur.\n",
      "1  :   Tu compliques à dire, de temps plus que c'est pas complètement un processeur.\n",
      "2  :   Dans le sens où il y a carrément une sortie, il y a un affichage, il y a de la rampe alors que la rampe serait plutôt en dehors dans un processeur.\n",
      "3  :   Mais c'est en fait une machine, ça se dit « Tourine complique ».\n",
      "4  :   Donc il faut réd définir ce que c'est qu'une machine de Tourine.\n",
      "5  :   C'est un concept typothétique créé par Alan Tourine en 1936.\n",
      "6  :   Et qui nous définit une bande de papier infinie, composée de plein de casse,\n",
      "1  :   et une tête de lecture qui peut écrire sur une casse.\n"
     ]
    }
   ],
   "source": [
    "# !pip install ollama \n",
    "\n",
    "def display_conversations_from_json(json_file):\n",
    "    # Charger les données JSON depuis le fichier\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Initialiser un dictionnaire pour stocker les conversations par locuteur\n",
    "    conversations = {}\n",
    "    \n",
    "    # Parcourir chaque message dans les données JSON\n",
    "    for message in data:\n",
    "        speaker_id = message[\"speaker\"]\n",
    "        text = message[\"text\"]\n",
    "        # Ajouter le message au locuteur correspondant dans le dictionnaire des conversations\n",
    "        if speaker_id in conversations:\n",
    "            conversations[speaker_id].append(text)\n",
    "        else:\n",
    "            conversations[speaker_id] = [text]\n",
    "    \n",
    "    # Afficher les conversations par locuteur\n",
    "    for speaker_id, messages in conversations.items():\n",
    "        # st.subheader(f\"Conversation avec le locuteur {speaker_id}\")\n",
    "        for i, message in enumerate(messages, start=1):\n",
    "            # st.write(f\"{i}. {message}\")\n",
    "            print(i , \" : \", message)\n",
    "    \n",
    "json_name = \"meeting_transcript.json\"\n",
    "display_conversations_from_json(json_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b45417c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A student, Simon, presented a project to design and build their own processor. The challenge was seen as significant, as the processor is the central element of a computer and one of the most complex components. Simon showed a mockup of their design and explained how they plan to implement it. The group discussed the details of the project, with some members expressing skepticism about whether what Simon had built could truly be called a processor. They also touched on the concept of Turing Machine, which was coined by Alan Turing in 1936. It seems that Simon's goal is not only to build a processor but also to understand how it works and learn from the experience. The group seemed supportive of Simon's project and offered to help in any way they could.\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install -r requirements_meetsum.txt\n",
    "\n",
    "\n",
    "json_name = \"meeting_transcript.json\"\n",
    "# main_meetsum.load_conversation_data(json_name)\n",
    "main_meetsum.meeting_summary_rest(json_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "997b85fa-fe47-4a7d-bd3f-25fee5bbb6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_speakers(model, path, num_speakers=2):\n",
    "    \"\"\"Do diarization with speaker names\"\"\"\n",
    "    \n",
    "    mono = 'test.wav'\n",
    "    cmd = 'ffmpeg -i {} -y -ac 1 test.wav'.format(path)\n",
    "    subprocess.check_output(cmd, shell=True)\n",
    "    result = model.transcribe(mono)\n",
    "    segments = result[\"segments\"]\n",
    "    \n",
    "    with contextlib.closing(wave.open(mono,'r')) as f:\n",
    "      frames = f.getnframes()\n",
    "      rate = f.getframerate()\n",
    "      duration = frames / float(rate)\n",
    "        \n",
    "    audio = Audio()\n",
    "    def segment_embedding(segment):\n",
    "        start = segment[\"start\"]\n",
    "        # Whisper overshoots the end timestamp in the last segment\n",
    "        end = min(duration, segment[\"end\"])\n",
    "        clip = Segment(start, end)\n",
    "        waveform, sample_rate = audio.crop(mono, clip)\n",
    "        return embedding_model(waveform[None])\n",
    "\n",
    "    embeddings = np.zeros(shape=(len(segments), 192))\n",
    "    for i, segment in enumerate(segments):\n",
    "      embeddings[i] = segment_embedding(segment)\n",
    "    embeddings = np.nan_to_num(embeddings)\n",
    "    \n",
    "    clustering = AgglomerativeClustering(num_speakers).fit(embeddings)\n",
    "    labels = clustering.labels_\n",
    "    for i in range(len(segments)):\n",
    "      segments[i][\"speaker\"] = 'SPEAKER ' + str(labels[i] + 1)\n",
    "    return segments    \n",
    "\n",
    "def write_segments(segments, outfile):\n",
    "    \"\"\"write out segments to file\"\"\"\n",
    "    \n",
    "    def time(secs):\n",
    "      return datetime.timedelta(seconds=round(secs))\n",
    "    print(len(segments))\n",
    "    f = open(outfile, \"w\")    \n",
    "    f.write(\"[ \\n \")\n",
    "    for (i, segment) in enumerate(segments):\n",
    "      # if i == 0 or segments[i - 1][\"seek\"] != segment[\"seek\"]:\n",
    "      f.write(\"{  \\n \")\n",
    "      f.write(f'  \\n  \"speaker\" : \"{str(segment[\"seek\"])}\" ,    ' )\n",
    "      f.write(f'  \\n  \"text\" : \" {str(segment[\"text\"])} \" \\n ' )\n",
    "      if i!=len(segments)-1 : \n",
    "        f.write(\"}, \\n \")\n",
    "      else : \n",
    "        f.write(\"} \\n \")\n",
    "    f.write(\"\\n]\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c403c9ce-728d-473f-ab9b-2cab0c4712e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "# seg = extract_speakers(model, 'test.wav')\n",
    "write_segments(segments, 'transcript.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c5defe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transcript.json', 'r') as f:\n",
    "    transcript_content = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b706a8f-f54f-483b-a914-34b428a798e5",
   "metadata": {},
   "source": [
    "## convert mp4 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd99584-a037-4c4f-bdb4-676517502469",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('*.wav')\n",
    "for f in files:\n",
    "    name=os.path.splitext(f)[0]        \n",
    "    out = '%s.txt' %name\n",
    "    if not os.path.exists(out):\n",
    "        print (name)\n",
    "        seg = extract_speakers(model, f)\n",
    "        write_segments(seg, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842bbabb-af0f-4c61-9637-7c1ab341dfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel3.10.14",
   "language": "python",
   "name": "kernel3.10.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
